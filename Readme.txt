ğŸ—‘ï¸ YOLOv8 Garbage Detection â€” Input Size Comparison

This repository contains a full lab report and results for YOLOv8-based garbage detection, comparing two input resolutions (416Ã—416 vs. 608Ã—608) to measure accuracy, recall, inference speed, and training cost.

If you need the YOLOv8 training notebook (.ipynb), contact me here:
ğŸ“§ amirthaganeshramesh@gmail.com

ğŸ“¦ Dataset Summary

Dataset: Garbage Detection (Roboflow)
Total Images: 1,255
Classes: 1 (garbage)

Split:

Training: 1,155 (92%)

Validation: 50 (4%)

Testing: 50 (4%)

Key Characteristics:

YOLOv8/YOLO11-compatible format

Varying image resolutions

Bounding-box annotations

Single-class dataset â†’ higher importance of recall

âš™ï¸ Experimental Setup
âœ… Model Architecture

Model: YOLOv8n (Nano)

Framework: Ultralytics YOLOv8

Pretrained Weights: COCO

Hardware: NVIDIA Tesla T4 (15GB VRAM)

Batch Size: 32

âœ… Training Configurations
Baseline â€” 416Ã—416

Epochs: 10

Training Time: 1.99 min

Device: GPU

Experiment â€” 608Ã—608

Epochs: 10

Training Time: 3.23 min

Device: GPU

ğŸ“Š Results
ğŸ” Performance Metrics Comparison
Metric	416Ã—416	608Ã—608	Change
mAP@0.5	0.3520	0.3630	+3.1%
mAP@0.5:0.95	0.1420	0.1490	+4.9%
Precision	0.5550	0.4900	âˆ’11.7%
Recall	0.3220	0.4000	+24.2%
Inference Time	1.3 ms	2.6 ms	+100%
Training Time	1.99 min	3.23 min	+62.3%
âœ… Key Observations

608Ã—608 catches more garbage objects (higher recall).

416Ã—416 has fewer false positives (higher precision).

608Ã—608 improves mAP but costs double inference time.

Both are real-time on GPU; CPU is too slow for deployment.

ğŸ§  Analysis & Discussion
â­ Advantages of 416Ã—416

Fastest inference

More precise (fewer false alarms)

Best for edge devices / low compute

â­ Advantages of 608Ã—608

Detects more garbage

Higher mAP

More robust to scale variations

Best for accuracy-critical applications

ğŸš€ GPU vs CPU

GPU training: 2â€“3 minutes

CPU training: 30â€“50 minutes (15â€“25Ã— slower)

GPU inference: 380â€“770 FPS

CPU inference: not real-time

ğŸ–¼ï¸ Qualitative Results

Observed trends:

608Ã—608 detects more small objects

416Ã—416 produces fewer false positives

Both perform well on mixed garbage scenes

âœ… Conclusion
Final Takeaways

608Ã—608 improves detection rate by +24.2%

416Ã—416 is faster but slightly less accurate

GPU acceleration is essential for practical experimentation

Best input size depends on your deployment needs

âœ… Recommendations
For Production Deployment

Use 608Ã—608 (higher recall + better accuracy).

For Edge Devices

Use 416Ã—416 (speed-optimized).

For Mobile Apps

Use quantized models (8-bit or FP16).

For Future Work

Try input size 512Ã—512 (middle ground)

Test larger YOLOv8 models (s/m/l/x)

Add pruning + quantization

Expand dataset

ğŸ“§ Need the YOLOv8 Notebook (.ipynb)?

Contact: amirthaganeshramesh@gmail.com
